{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Hand Gestures\n",
    "\n",
    "In this notebook, we train and evaluate different classification models for the task of hand gesture classification. We use the data generated in the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reload custom scripts automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "# Modelling\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = os.path.join(\"..\", \"data\")\n",
    "NINAPRO_ROOT = os.path.join(\"..\", \"data\", \"ninapro\")\n",
    "SAMPLING_EMG_RATE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data preprocessed in the previous notebook\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading the data, make sure you downloaded them ([link](https://drive.google.com/file/d/1tz8tb6rruNvnlBkwDc80aT7D8jAXvwkF/view?usp=sharing)) and placed them into the data folder! \n",
    "\n",
    "We start by loading the data preprocessed in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded data, there are 27 subjects.\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(DATA_ROOT, \"exercise_1_processed.pkl\"), 'rb') as file:\n",
    "    subjects_features = pickle.load(file)\n",
    "\n",
    "print(\"✅ Successfully loaded data, there are {} subjects.\".format(len(subjects_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check what we get for instance for first subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Number of windows: 10143 (train), 5984 (val), 3977 (test)\n",
      "ℹ️ All have 120 features.\n"
     ]
    }
   ],
   "source": [
    "# Get the data for the first subject\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = subjects_features[1]\n",
    "\n",
    "# Print the shapes of the data\n",
    "print(f\"ℹ️ Number of windows: {X_train.shape[0]} (train), {X_val.shape[0]} (val), {X_test.shape[0]} (test)\")\n",
    "print(f\"ℹ️ All have {X_train.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Eval the Models (One Subject)\n",
    "\n",
    "---\n",
    "\n",
    "In this section, we try to train and then evaluate the model on the data from 10 subjects. Note that these subjeocts will remain same for training as well as validation. We will train separate models for each subject and then evaluate them on the test data of the same subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select randmly 10 subjects\n",
    "selected_subjects = random.sample(list(subjects_features.keys()), 10)\n",
    "\n",
    "# Collect the data for the selected subjects\n",
    "selected = dict()\n",
    "for subject in selected_subjects:\n",
    "    # Get the data for the subject\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = subjects_features[subject]\n",
    "\n",
    "    # Impute the missing values for features\n",
    "    X_train = utils.impute_missing_values(X_train)\n",
    "    X_val = utils.impute_missing_values(X_val)\n",
    "    X_test = utils.impute_missing_values(X_test)\n",
    "\n",
    "    # Add the data to the dictionary\n",
    "    selected[subject] = (X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:35<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define the models storage for each subject\n",
    "models = dict()\n",
    "\n",
    "for subject in tqdm(selected.keys()):\n",
    "\n",
    "    # Get the train data\n",
    "    X_train, y_train, _, _, _, _ = selected[subject]\n",
    "\n",
    "    # Define the pipeline\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),  \n",
    "        ('logistic regression', SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=100))\n",
    "    ])\n",
    "\n",
    "    # Train the pipeline on the training data\n",
    "    model.fit(X_train, y_train);\n",
    "\n",
    "    # Add the model to the dictionary\n",
    "    models[subject] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the model on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 77.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Subject 18 - Train acc: 0.767, Val acc: 0.717\n",
      "ℹ️ Subject 25 - Train acc: 0.811, Val acc: 0.785\n",
      "ℹ️ Subject 23 - Train acc: 0.801, Val acc: 0.746\n",
      "ℹ️ Subject 26 - Train acc: 0.814, Val acc: 0.799\n",
      "ℹ️ Subject 4 - Train acc: 0.793, Val acc: 0.743\n",
      "ℹ️ Subject 21 - Train acc: 0.888, Val acc: 0.862\n",
      "ℹ️ Subject 19 - Train acc: 0.820, Val acc: 0.745\n",
      "ℹ️ Subject 12 - Train acc: 0.797, Val acc: 0.738\n",
      "ℹ️ Subject 24 - Train acc: 0.886, Val acc: 0.826\n",
      "ℹ️ Subject 2 - Train acc: 0.870, Val acc: 0.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for subject in tqdm(selected.keys()):\n",
    "\n",
    "    # Get the data on which we want to evaluate the model\n",
    "    X_train, y_train, X_val, y_val, _, _ = selected[subject]\n",
    "\n",
    "    # Get the model\n",
    "    model = models[subject]\n",
    "\n",
    "    # Make predictions on the train and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"ℹ️ Subject {subject} - Train acc: {train_acc:.3f}, Val acc: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emg-signal-movement-clf-5pn15elU-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
